---
title: "Statistical disclosure control"
author: "Thom Benjamin Volker"
---

# Introduction

Collected research data often contains sensitive information about individuals. 
For example, social scientists might collect data on income or criminal behavior, and health data might contain sensitive information about patients.
Such private information may harm individuals if disclosed to the public.
Even if no harm is incurred, the trust of individuals in the data collector, or scientific institutions in general, may be damaged if such data is revealed. 
At the same time, collected data is very valuable to researchers and governmental institutions alike.
Using previously collected data, researchers may answer novel research questions and governmental institutions may improve policy. 
In addition to these high-level applications, open data can also be used to evaluate the reproducibility of research projects or serve as realistic data in education.
That is, open data is valuable for many applications, but simply releasing the data is often not an option.

The first step in the process of releasing data is to anonymize it [TODO: see Data Anonymization tutorial]. 
Anonymization requires that potentially identifying information is removed from the collected data (e.g., names, addresses, IP-addresses). 
After de-identifying the data, your data might still contain information that can lead to indirect identification of individuals, for example because the data can be linked to external data sources.
Especially in today's age of massive data collection, data sources can be linked in surprising ways.
For example, in 2006, researchers from the University of Texas were able to uncover the identity of Netflix users by linking Netflix movie reviews to the IMDB database.
To prevent such indirect identification, statistical disclosure control can be applied to the data.

The goal of statistical disclosure control is to release a dataset that is as similar as possible to the original data, while at the same time ensuring that no individual can be identified from the released data, nor any sensitive information can be inferred [@]. 
Several techniques exist to achieve this goal, including masking, swapping, noise addition and rounding. 
However, without taking these alterations into account, relationships between variables in the data may be distorted, limiting their usefulness.
In this tutorial, we focus ourselves on the generation of synthetic data as a means of statistical disclosure control.


The idea of synthetic data is that the observed values are replaced by values that are generated from a model.
This model is fitted to the observed data, and generated values are drawn from this fitted model. 
Thus, the amount of information contained in the synthetic data is limited to the information contained in the synthesis model. 

Depending on the model used, the protection against disclosure can be very strong. 
, which limits disclosure risks while preserving relationships between variables. 
Thus, as far as the relationships between variables are modelled correctly, synthetic data yields valid inferences. 


# Level One Header

## Level Two

### L3

### L3 Again

### And one more time

## Another Level Two


# Level One Again

## Level Two
